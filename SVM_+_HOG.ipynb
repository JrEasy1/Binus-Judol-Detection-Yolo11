{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from joblib import dump, load\n",
        "import zipfile\n"
      ],
      "metadata": {
        "id": "LE-rXii0CnHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = '/content/Judol Detection v2.v9i.yolov11.zip'\n",
        "\n",
        "destination_path = '/content/dataset'\n",
        "\n",
        "os.makedirs(destination_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination_path)\n",
        "\n",
        "print(f\"Files extracted to {destination_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeQC78gmaTFa",
        "outputId": "8a414262-40ea-4ef5-9297-65c523d5f8c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to /content/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_path = \"dataset/train/images\"\n",
        "train_labels_path = \"dataset/train/labels\"\n",
        "val_images_path = \"dataset/valid/images\"\n",
        "val_labels_path = \"dataset/valid/labels\"\n",
        "test_images_path = \"dataset/test/images\"\n",
        "test_labels_path = \"dataset/test/labels\"\n",
        "output_images_path = \"predicted_images\"\n",
        "output_video_path = \"predicted_video.mp4\"\n",
        "\n",
        "class_names = {\n",
        "    0: \"BK8\",\n",
        "    1: \"Gate of Olympus\",\n",
        "    2: \"Starlight Princess\",\n",
        "    3: \"Princess\",\n",
        "    4: \"Zeus\",\n",
        "}\n",
        "\n",
        "WINDOW_SIZE = (128, 128)\n",
        "STEP_SIZE = 64"
      ],
      "metadata": {
        "id": "ilDLs_OUCu8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_hog(image):\n",
        "    hog = cv2.HOGDescriptor(\n",
        "        _winSize=(128, 128), _blockSize=(16, 16), _blockStride=(8, 8),\n",
        "        _cellSize=(8, 8), _nbins=9\n",
        "    )\n",
        "    return hog.compute(image).flatten()\n",
        "\n",
        "\n",
        "def compute_iou(box1, box2):\n",
        "\n",
        "    x1_inter = max(box1[0], box2[0])\n",
        "    y1_inter = max(box1[1], box2[1])\n",
        "    x2_inter = min(box1[2], box2[2])\n",
        "    y2_inter = min(box1[3], box2[3])\n",
        "\n",
        "\n",
        "    intersection_area = max(0, x2_inter - x1_inter) * max(0, y2_inter - y1_inter)\n",
        "\n",
        "\n",
        "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "\n",
        "\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "\n",
        "\n",
        "    iou = intersection_area / union_area\n",
        "    return iou\n",
        "\n",
        "def image_pyramid(image, scale=1.5, min_size=(30, 30)):\n",
        "    yield image\n",
        "    while True:\n",
        "\n",
        "        width = int(image.shape[1] / scale)\n",
        "        height = int(image.shape[0] / scale)\n",
        "\n",
        "        if width < min_size[0] or height < min_size[1]:\n",
        "            break\n",
        "\n",
        "        image = cv2.resize(image, (width, height))\n",
        "        yield image"
      ],
      "metadata": {
        "id": "sHc1iWZUC1Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(images_path, labels_path):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for image_file in os.listdir(images_path):\n",
        "        if image_file.endswith(\".jpg\"):\n",
        "            image_path = os.path.join(images_path, image_file)\n",
        "            label_path = os.path.join(labels_path, image_file.replace(\".jpg\", \".txt\"))\n",
        "\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            h, w = image.shape\n",
        "\n",
        "            with open(label_path, \"r\") as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    class_id = int(parts[0])\n",
        "                    x_center, y_center, width, height = map(float, parts[1:])\n",
        "                    x1 = int((x_center - width / 2) * w)\n",
        "                    y1 = int((y_center - height / 2) * h)\n",
        "                    x2 = int((x_center + width / 2) * w)\n",
        "                    y2 = int((y_center + height / 2) * h)\n",
        "\n",
        "                    roi = image[y1:y2, x1:x2]\n",
        "                    if roi.size > 0:\n",
        "                        roi_resized = cv2.resize(roi, WINDOW_SIZE)\n",
        "                        features.append(compute_hog(roi_resized))\n",
        "                        labels.append(class_id)\n",
        "\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "\n",
        "def sliding_window(image, step_size, window_size):\n",
        "    for y in range(0, image.shape[0] - window_size[1], step_size):\n",
        "        for x in range(0, image.shape[1] - window_size[0], step_size):\n",
        "            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])"
      ],
      "metadata": {
        "id": "uIJYTKMxDDvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def non_max_suppression(detections, iou_threshold=0.3):\n",
        "\n",
        "    detections = sorted(detections, key=lambda x: x[5], reverse=True)\n",
        "\n",
        "    suppressed = []\n",
        "\n",
        "    while detections:\n",
        "\n",
        "        current_detection = detections.pop(0)\n",
        "        current_box = current_detection[:4]\n",
        "\n",
        "\n",
        "        suppressed.append(current_detection)\n",
        "\n",
        "        detections = [det for det in detections if compute_iou(current_box, det[:4]) < iou_threshold]\n",
        "\n",
        "    return suppressed\n",
        "\n",
        "\n",
        "\n",
        "def visualize_detections(image, detections, ground_truth_boxes=None):\n",
        "\n",
        "    for (x1, y1, x2, y2, class_id, confidence) in detections:\n",
        "        color = (0, 255, 0)\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "\n",
        "        cv2.putText(image, f\"{class_names[class_id]}: {confidence:.2f}\",\n",
        "                    (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "\n",
        "    if ground_truth_boxes:\n",
        "        for (x1, y1, x2, y2) in ground_truth_boxes:\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "\n",
        "def detect_objects(image, model, confidence_threshold=0.9):\n",
        "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    detections = []\n",
        "\n",
        "    for resized_image in image_pyramid(image_gray, scale=1.5):\n",
        "        for (x, y, window) in sliding_window(resized_image, STEP_SIZE, WINDOW_SIZE):\n",
        "            if window.shape[:2] != WINDOW_SIZE:\n",
        "                continue\n",
        "\n",
        "            features = compute_hog(window)\n",
        "            prediction = model.predict([features])[0]\n",
        "            confidence = model.predict_proba([features])[0][prediction]\n",
        "\n",
        "            if confidence > confidence_threshold:\n",
        "                scale_factor = image_gray.shape[0] / resized_image.shape[0]\n",
        "                x1 = int(x * scale_factor)\n",
        "                y1 = int(y * scale_factor)\n",
        "                x2 = int((x + WINDOW_SIZE[0]) * scale_factor)\n",
        "                y2 = int((y + WINDOW_SIZE[1]) * scale_factor)\n",
        "\n",
        "                detections.append((x1, y1, x2, y2, prediction, confidence))\n",
        "\n",
        "    detections = non_max_suppression(detections)\n",
        "    return detections"
      ],
      "metadata": {
        "id": "HdHf71XmDVcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = prepare_dataset(train_images_path, train_labels_path)\n",
        "print(f\"Training data: {len(X_train)} samples\")\n",
        "\n",
        "X_val, y_val = prepare_dataset(val_images_path, val_labels_path)\n",
        "print(f\"Validation data: {len(X_val)} samples\")\n",
        "\n",
        "print(\"Training SVM...\")\n",
        "svm = SVC(kernel='rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "print(\"SVM training completed.\")\n",
        "\n",
        "X_test, y_test = prepare_dataset(test_images_path, test_labels_path)\n",
        "test_predictions = svm.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(f\"Test accuracy: {test_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "fZXE_OtKDMRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video(input_video_path, output_video_path, model):\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, 30, (640, 480))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        detections = detect_objects(frame, model)\n",
        "        result_frame = visualize_detections(frame, detections)\n",
        "\n",
        "        out.write(result_frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "def visualize_and_save_gradients(image_path, output_path):\n",
        "\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if image is None:\n",
        "        print(f\"Failed to load {image_path}\")\n",
        "        return\n",
        "\n",
        "\n",
        "    grad_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
        "    grad_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
        "\n",
        "\n",
        "    magnitude = np.sqrt(grad_x ** 2 + grad_y ** 2)\n",
        "    angle = np.arctan2(grad_y, grad_x) * (180 / np.pi) % 360\n",
        "\n",
        "\n",
        "    magnitude_norm = (magnitude / magnitude.max()) * 255\n",
        "    magnitude_norm = magnitude_norm.astype(np.uint8)\n",
        "\n",
        "\n",
        "    filename = os.path.basename(image_path)\n",
        "    filename_no_ext = os.path.splitext(filename)[0]\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.imshow(image, cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title(\"Gradient Magnitude\")\n",
        "    plt.imshow(magnitude_norm, cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title(\"Gradient Orientation\")\n",
        "    plt.imshow(angle, cmap=\"hsv\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "\n",
        "    output_file = os.path.join(output_path, f\"{filename_no_ext}_gradients.png\")\n",
        "    plt.savefig(output_file)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Saved gradient visualization for {filename} to {output_file}\")"
      ],
      "metadata": {
        "id": "OYKZsVQBDs6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fR5VEXiDYFtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18271c3-28b4-4fd8-a02b-1b2c18159728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing training data...\n",
            "Training data: 1971 samples\n",
            "Preparing validation data...\n",
            "Validation data: 177 samples\n",
            "Training SVM...\n",
            "SVM training completed.\n",
            "Test accuracy: 0.97\n",
            "Processed bk8_jpg.rf.7ffab985073d109b16e18625b5988f0c.jpg\n",
            "Processed maxresdefault-18-_jpg.rf.2439a6fa40b31753e4621fa98ddb54b4.jpg\n",
            "Processed hq720-32-_jpg.rf.f5ffaf4faf04da11804763247e877862.jpg\n",
            "Processed 467155472_122105823158610608_4654678954588885548_n_jpg.rf.8ccdd073b18be3c6d4626c293f4dc834.jpg\n",
            "Processed hq720-69-_jpg.rf.11c96a2213a964692960e2e506c33967.jpg\n",
            "Processed Screenshot-2024-12-14-192520_png.rf.95cdaaae4492e824b38c8a4e5a908022.jpg\n",
            "Processed 33199069_2105952949681663_4193847788573818880_n_jpg.rf.983b10d9de92dc8952811d50008812f2.jpg\n",
            "Processed GB7JdnwWgAAq2rb_jpg.rf.db2f7dfc7e6230faf8d3907e2cddef69.jpg\n",
            "Processed 0a3c7711d581c552971470fc30975ba7_jpg.rf.9c29b60d0598fc5273847f5bda4a7082.jpg\n",
            "Processed hq720-21-_jpg.rf.f13c0fa45ebb25d64da56ab16240b065.jpg\n",
            "Processed hq720-40-_jpg.rf.f329237ab8c191c5f5e6fc30c4111cca.jpg\n",
            "Processed 470181870_122115605018610608_5781749290101276282_n_jpg.rf.d0305e6ca2493b04b407ccff76a28d35.jpg\n",
            "Processed 33207223_2105990819677876_3495818790115999744_n_png.rf.cc2431aa533ab4bcd4259dd010c6af1d.jpg\n",
            "Processed hq720-29-_jpg.rf.0a7bfc727059ddd22f74f3c3e387f70d.jpg\n",
            "Processed maxresdefault-9-_jpg.rf.dd770cb1cf2d40a85b00425e30573897.jpg\n",
            "Processed maxresdefault-10-_jpg.rf.e721dd79242e0ce56079a883c6eaad8f.jpg\n",
            "Processed unnamed_png.rf.61c45fe85c172fb4642f935cdc320615.jpg\n",
            "Processed 37660301_2159159871027637_6561477338314309632_n_jpg.rf.65d823cd1d0329f27c3842cac5051011.jpg\n",
            "Processed 448264960_1519635528937806_8749616790365129167_n_jpg.rf.e45dc36dd474515638a4b44bd01872c3.jpg\n",
            "Processed hq720-62-_jpg.rf.7a7f10806db5e3f9ccbc5e318c30ecc0.jpg\n",
            "Processed maxresdefault-5-_jpg.rf.cfb16340cd056acc140ef9c7dca30476.jpg\n",
            "Processed 1a0c95cf-ce84-4e5e-98c0-6ccf0d304e53_png.rf.6de0d68756b5598f686b2cd1ce49675b.jpg\n",
            "Processed hq720-72-_jpg.rf.23f5fe491e0d0c168a6d69b8c0aff134.jpg\n",
            "Processed hq720-23-_jpg.rf.20209735a28fcd7aa99af57ed7505860.jpg\n",
            "Processed maxresdefault-16-_jpg.rf.1b2d789ff076bcbff4b233393629b0b2.jpg\n",
            "Processed hq720-66-_jpg.rf.2216edcef60e3c6d026f64d39844a416.jpg\n",
            "Processed hq720-29-_jpg.rf.e8e4a94a87310de3cb6d26312c26ae38.jpg\n",
            "Processed maxresdefault-13-_jpg.rf.db5a7f85ee5322b3655fcc34a70d9e1d.jpg\n",
            "Processed hq720-22-_jpg.rf.b6275141a45cb8cf882a02bb343e8ddf.jpg\n",
            "Processed hq720-79-_jpg.rf.83ee37ededbcecca3c57cd560f0548c0.jpg\n",
            "Processed maxresdefault-17-_jpg.rf.b4d23ef9a3edb05e035b243fa390b925.jpg\n",
            "Processed hq720-5-_jpg.rf.c04acdf6af547a893a15038ea1e14503.jpg\n",
            "Processed maxresdefault-21-_jpg.rf.4479d2089590007e2bdbfe18973236a7.jpg\n",
            "Processed Screenshot-2024-12-14-233455_png.rf.399ac7ef98ba8a90987fdf50407bce74.jpg\n",
            "Processed hq720-47-_jpg.rf.9c071f0d10476fbc4212c9875b8de46b.jpg\n",
            "Processed maxresdefault-11-_jpg.rf.0fdaffd11662438cc8d49fae52df6f32.jpg\n",
            "Processed hq720-28-_jpg.rf.f0335d14f5dc8b2d26e68f0002b988cf.jpg\n",
            "Processed Screenshot-2024-12-14-193253_png.rf.f072d7c6a6c67df21f88d9c55e5767fe.jpg\n",
            "Processed Screenshot-2024-12-14-233012_png.rf.bb9a57a436fdf59a942970b4b68bef03.jpg\n",
            "Processed hq720_jpg.rf.fd3afe125e4b154d66bec462c19e68a0.jpg\n",
            "Saved gradient visualization for bk8_jpg.rf.7ffab985073d109b16e18625b5988f0c.jpg to gradient_visualization/bk8_jpg.rf.7ffab985073d109b16e18625b5988f0c_gradients.png\n",
            "Saved gradient visualization for maxresdefault-18-_jpg.rf.2439a6fa40b31753e4621fa98ddb54b4.jpg to gradient_visualization/maxresdefault-18-_jpg.rf.2439a6fa40b31753e4621fa98ddb54b4_gradients.png\n",
            "Saved gradient visualization for hq720-32-_jpg.rf.f5ffaf4faf04da11804763247e877862.jpg to gradient_visualization/hq720-32-_jpg.rf.f5ffaf4faf04da11804763247e877862_gradients.png\n",
            "Saved gradient visualization for 467155472_122105823158610608_4654678954588885548_n_jpg.rf.8ccdd073b18be3c6d4626c293f4dc834.jpg to gradient_visualization/467155472_122105823158610608_4654678954588885548_n_jpg.rf.8ccdd073b18be3c6d4626c293f4dc834_gradients.png\n",
            "Saved gradient visualization for hq720-69-_jpg.rf.11c96a2213a964692960e2e506c33967.jpg to gradient_visualization/hq720-69-_jpg.rf.11c96a2213a964692960e2e506c33967_gradients.png\n",
            "Saved gradient visualization for Screenshot-2024-12-14-192520_png.rf.95cdaaae4492e824b38c8a4e5a908022.jpg to gradient_visualization/Screenshot-2024-12-14-192520_png.rf.95cdaaae4492e824b38c8a4e5a908022_gradients.png\n",
            "Saved gradient visualization for 33199069_2105952949681663_4193847788573818880_n_jpg.rf.983b10d9de92dc8952811d50008812f2.jpg to gradient_visualization/33199069_2105952949681663_4193847788573818880_n_jpg.rf.983b10d9de92dc8952811d50008812f2_gradients.png\n",
            "Saved gradient visualization for GB7JdnwWgAAq2rb_jpg.rf.db2f7dfc7e6230faf8d3907e2cddef69.jpg to gradient_visualization/GB7JdnwWgAAq2rb_jpg.rf.db2f7dfc7e6230faf8d3907e2cddef69_gradients.png\n",
            "Saved gradient visualization for 0a3c7711d581c552971470fc30975ba7_jpg.rf.9c29b60d0598fc5273847f5bda4a7082.jpg to gradient_visualization/0a3c7711d581c552971470fc30975ba7_jpg.rf.9c29b60d0598fc5273847f5bda4a7082_gradients.png\n",
            "Saved gradient visualization for hq720-21-_jpg.rf.f13c0fa45ebb25d64da56ab16240b065.jpg to gradient_visualization/hq720-21-_jpg.rf.f13c0fa45ebb25d64da56ab16240b065_gradients.png\n",
            "Saved gradient visualization for hq720-40-_jpg.rf.f329237ab8c191c5f5e6fc30c4111cca.jpg to gradient_visualization/hq720-40-_jpg.rf.f329237ab8c191c5f5e6fc30c4111cca_gradients.png\n",
            "Saved gradient visualization for 470181870_122115605018610608_5781749290101276282_n_jpg.rf.d0305e6ca2493b04b407ccff76a28d35.jpg to gradient_visualization/470181870_122115605018610608_5781749290101276282_n_jpg.rf.d0305e6ca2493b04b407ccff76a28d35_gradients.png\n",
            "Saved gradient visualization for 33207223_2105990819677876_3495818790115999744_n_png.rf.cc2431aa533ab4bcd4259dd010c6af1d.jpg to gradient_visualization/33207223_2105990819677876_3495818790115999744_n_png.rf.cc2431aa533ab4bcd4259dd010c6af1d_gradients.png\n",
            "Saved gradient visualization for hq720-29-_jpg.rf.0a7bfc727059ddd22f74f3c3e387f70d.jpg to gradient_visualization/hq720-29-_jpg.rf.0a7bfc727059ddd22f74f3c3e387f70d_gradients.png\n",
            "Saved gradient visualization for maxresdefault-9-_jpg.rf.dd770cb1cf2d40a85b00425e30573897.jpg to gradient_visualization/maxresdefault-9-_jpg.rf.dd770cb1cf2d40a85b00425e30573897_gradients.png\n",
            "Saved gradient visualization for maxresdefault-10-_jpg.rf.e721dd79242e0ce56079a883c6eaad8f.jpg to gradient_visualization/maxresdefault-10-_jpg.rf.e721dd79242e0ce56079a883c6eaad8f_gradients.png\n",
            "Saved gradient visualization for unnamed_png.rf.61c45fe85c172fb4642f935cdc320615.jpg to gradient_visualization/unnamed_png.rf.61c45fe85c172fb4642f935cdc320615_gradients.png\n",
            "Saved gradient visualization for 37660301_2159159871027637_6561477338314309632_n_jpg.rf.65d823cd1d0329f27c3842cac5051011.jpg to gradient_visualization/37660301_2159159871027637_6561477338314309632_n_jpg.rf.65d823cd1d0329f27c3842cac5051011_gradients.png\n",
            "Saved gradient visualization for 448264960_1519635528937806_8749616790365129167_n_jpg.rf.e45dc36dd474515638a4b44bd01872c3.jpg to gradient_visualization/448264960_1519635528937806_8749616790365129167_n_jpg.rf.e45dc36dd474515638a4b44bd01872c3_gradients.png\n",
            "Saved gradient visualization for hq720-62-_jpg.rf.7a7f10806db5e3f9ccbc5e318c30ecc0.jpg to gradient_visualization/hq720-62-_jpg.rf.7a7f10806db5e3f9ccbc5e318c30ecc0_gradients.png\n",
            "Saved gradient visualization for maxresdefault-5-_jpg.rf.cfb16340cd056acc140ef9c7dca30476.jpg to gradient_visualization/maxresdefault-5-_jpg.rf.cfb16340cd056acc140ef9c7dca30476_gradients.png\n",
            "Saved gradient visualization for 1a0c95cf-ce84-4e5e-98c0-6ccf0d304e53_png.rf.6de0d68756b5598f686b2cd1ce49675b.jpg to gradient_visualization/1a0c95cf-ce84-4e5e-98c0-6ccf0d304e53_png.rf.6de0d68756b5598f686b2cd1ce49675b_gradients.png\n",
            "Saved gradient visualization for hq720-72-_jpg.rf.23f5fe491e0d0c168a6d69b8c0aff134.jpg to gradient_visualization/hq720-72-_jpg.rf.23f5fe491e0d0c168a6d69b8c0aff134_gradients.png\n",
            "Saved gradient visualization for hq720-23-_jpg.rf.20209735a28fcd7aa99af57ed7505860.jpg to gradient_visualization/hq720-23-_jpg.rf.20209735a28fcd7aa99af57ed7505860_gradients.png\n",
            "Saved gradient visualization for maxresdefault-16-_jpg.rf.1b2d789ff076bcbff4b233393629b0b2.jpg to gradient_visualization/maxresdefault-16-_jpg.rf.1b2d789ff076bcbff4b233393629b0b2_gradients.png\n",
            "Saved gradient visualization for hq720-66-_jpg.rf.2216edcef60e3c6d026f64d39844a416.jpg to gradient_visualization/hq720-66-_jpg.rf.2216edcef60e3c6d026f64d39844a416_gradients.png\n",
            "Saved gradient visualization for hq720-29-_jpg.rf.e8e4a94a87310de3cb6d26312c26ae38.jpg to gradient_visualization/hq720-29-_jpg.rf.e8e4a94a87310de3cb6d26312c26ae38_gradients.png\n",
            "Saved gradient visualization for maxresdefault-13-_jpg.rf.db5a7f85ee5322b3655fcc34a70d9e1d.jpg to gradient_visualization/maxresdefault-13-_jpg.rf.db5a7f85ee5322b3655fcc34a70d9e1d_gradients.png\n",
            "Saved gradient visualization for hq720-22-_jpg.rf.b6275141a45cb8cf882a02bb343e8ddf.jpg to gradient_visualization/hq720-22-_jpg.rf.b6275141a45cb8cf882a02bb343e8ddf_gradients.png\n",
            "Saved gradient visualization for hq720-79-_jpg.rf.83ee37ededbcecca3c57cd560f0548c0.jpg to gradient_visualization/hq720-79-_jpg.rf.83ee37ededbcecca3c57cd560f0548c0_gradients.png\n",
            "Saved gradient visualization for maxresdefault-17-_jpg.rf.b4d23ef9a3edb05e035b243fa390b925.jpg to gradient_visualization/maxresdefault-17-_jpg.rf.b4d23ef9a3edb05e035b243fa390b925_gradients.png\n",
            "Saved gradient visualization for hq720-5-_jpg.rf.c04acdf6af547a893a15038ea1e14503.jpg to gradient_visualization/hq720-5-_jpg.rf.c04acdf6af547a893a15038ea1e14503_gradients.png\n",
            "Saved gradient visualization for maxresdefault-21-_jpg.rf.4479d2089590007e2bdbfe18973236a7.jpg to gradient_visualization/maxresdefault-21-_jpg.rf.4479d2089590007e2bdbfe18973236a7_gradients.png\n",
            "Saved gradient visualization for Screenshot-2024-12-14-233455_png.rf.399ac7ef98ba8a90987fdf50407bce74.jpg to gradient_visualization/Screenshot-2024-12-14-233455_png.rf.399ac7ef98ba8a90987fdf50407bce74_gradients.png\n",
            "Saved gradient visualization for hq720-47-_jpg.rf.9c071f0d10476fbc4212c9875b8de46b.jpg to gradient_visualization/hq720-47-_jpg.rf.9c071f0d10476fbc4212c9875b8de46b_gradients.png\n",
            "Saved gradient visualization for maxresdefault-11-_jpg.rf.0fdaffd11662438cc8d49fae52df6f32.jpg to gradient_visualization/maxresdefault-11-_jpg.rf.0fdaffd11662438cc8d49fae52df6f32_gradients.png\n",
            "Saved gradient visualization for hq720-28-_jpg.rf.f0335d14f5dc8b2d26e68f0002b988cf.jpg to gradient_visualization/hq720-28-_jpg.rf.f0335d14f5dc8b2d26e68f0002b988cf_gradients.png\n",
            "Saved gradient visualization for Screenshot-2024-12-14-193253_png.rf.f072d7c6a6c67df21f88d9c55e5767fe.jpg to gradient_visualization/Screenshot-2024-12-14-193253_png.rf.f072d7c6a6c67df21f88d9c55e5767fe_gradients.png\n",
            "Saved gradient visualization for Screenshot-2024-12-14-233012_png.rf.bb9a57a436fdf59a942970b4b68bef03.jpg to gradient_visualization/Screenshot-2024-12-14-233012_png.rf.bb9a57a436fdf59a942970b4b68bef03_gradients.png\n",
            "Saved gradient visualization for hq720_jpg.rf.fd3afe125e4b154d66bec462c19e68a0.jpg to gradient_visualization/hq720_jpg.rf.fd3afe125e4b154d66bec462c19e68a0_gradients.png\n",
            "All gradient visualizations saved in gradient_visualization\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(output_images_path, exist_ok=True)\n",
        "for image_file in os.listdir(test_images_path):\n",
        "    if image_file.endswith(\".jpg\"):\n",
        "        image_path = os.path.join(test_images_path, image_file)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        detections = detect_objects(image, svm)\n",
        "\n",
        "        label_path = os.path.join(test_labels_path, image_file.replace(\".jpg\", \".txt\"))\n",
        "        ground_truth_boxes = []\n",
        "        with open(label_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                x_center, y_center, width, height = map(float, parts[1:])\n",
        "                x1 = int((x_center - width / 2) * image.shape[1])\n",
        "                y1 = int((y_center - height / 2) * image.shape[0])\n",
        "                x2 = int((x_center + width / 2) * image.shape[1])\n",
        "                y2 = int((y_center + height / 2) * image.shape[0])\n",
        "                ground_truth_boxes.append((x1, y1, x2, y2))\n",
        "\n",
        "        result_image = visualize_detections(image, detections, ground_truth_boxes)\n",
        "\n",
        "        output_path = os.path.join(output_images_path, image_file)\n",
        "        cv2.imwrite(output_path, result_image)\n",
        "        print(f\"Processed {image_file}\")\n",
        "\n",
        "\n",
        "# Uncomment If want process video\n",
        "# process_video(\"input_video.mp4\", \"output_video.mp4\", svm)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "test_images_path = \"dataset/test/images\"\n",
        "gradient_output_path = \"gradient_visualization\"\n",
        "\n",
        "os.makedirs(gradient_output_path, exist_ok=True)\n",
        "\n",
        "for image_file in os.listdir(test_images_path):\n",
        "    if image_file.endswith(\".jpg\"):\n",
        "        image_path = os.path.join(test_images_path, image_file)\n",
        "        visualize_and_save_gradients(image_path, gradient_output_path)\n",
        "\n",
        "print(f\"All gradient visualizations saved in {gradient_output_path}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_and_save_gradients(\"cat.jpg\", gradient_output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOGJuLvygkbg",
        "outputId": "1b3b8246-5662-450e-fd08-94cb94e1eaa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved gradient visualization for cat.jpg to gradient_visualization/cat_gradients.png\n"
          ]
        }
      ]
    }
  ]
}